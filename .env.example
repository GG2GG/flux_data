# Retail Product Placement Agent - Environment Configuration
# Copy this file to .env and configure your settings

# ============================================================================
# LLM Configuration
# ============================================================================

# Option 1: OpenAI (recommended for production)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_API_BASE=https://api.openai.com/v1  # Optional: custom endpoint
LLM_MODEL=gpt-4o-mini
# LLM_MODEL=gpt-4o  # More capable but slower/costlier

# Option 2: OpenRouter (access to multiple models)
# Get your API key from: https://openrouter.ai/keys
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here
# LLM_MODEL=anthropic/claude-3.5-sonnet
# LLM_MODEL=google/gemini-pro
# LLM_MODEL=meta-llama/llama-3-70b-instruct

# Option 3: Local Ollama (no API key needed, use docker-compose.ollama.yml)
# OPENAI_API_KEY=ollama
# OPENAI_API_BASE=http://localhost:11434/v1
# LLM_MODEL=deepseek-r1:latest
# LLM_MODEL=qwen2.5:latest
# LLM_MODEL=llama3.1:latest

# LLM Generation Settings
LLM_TEMPERATURE=0.7      # 0.0 = deterministic, 1.0 = creative
LLM_MAX_TOKENS=1500      # Maximum response length

# ============================================================================
# API Configuration
# ============================================================================
PORT=8000
LOG_LEVEL=info           # debug, info, warning, error

# ============================================================================
# Data Configuration
# ============================================================================
DATA_DIR=./data
CONFIG_DIR=./config

# ============================================================================
# Future Enhancements (not yet implemented)
# ============================================================================
# REDIS_URL=redis://localhost:6379
# DATABASE_URL=postgresql://user:pass@localhost:5432/retail_db

# ============================================================================
# Notes
# ============================================================================
# - The system works without LLM (uses templates) but explanations are better with LLM
# - For production: Use OpenAI or OpenRouter with API keys
# - For local/offline: Use docker-compose.ollama.yml with local Ollama
# - Recommended models: gpt-4o-mini (fast/cheap) or claude-3.5-sonnet (best quality)
